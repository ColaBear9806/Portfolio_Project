{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6529e8-a361-42c9-9e9a-c21f2b94fbff",
   "metadata": {},
   "source": [
    "# 실행전 준비(git clone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4878d86a",
   "metadata": {},
   "source": [
    "데이터 출처: https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&dataSetSn=580"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00216026-a177-45c4-a0dc-9453963660fc",
   "metadata": {},
   "source": [
    "Colab이 아닌 로컬 아나콘다에서 실행시, HuggingFaceEmbeddings를 이용한 \n",
    "\n",
    "embedding model이 다운되지 않는 현상 발생\n",
    "\n",
    "따라서 모델을 git clone으로 직접 다운로드 후 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c4aedd-7e81-4134-bd65-b2d96a07b3b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!git clone https://huggingface.co/jhgan/ko-sroberta-multitask models/ko-sroberta-multitask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d24f14-f964-4e5e-bcab-7dd34d7d87d1",
   "metadata": {},
   "source": [
    "# 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "468ee810-9dd0-44ca-8b5f-ffecd80ba25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 출처: https://aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&dataSetSn=580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a78dc-20f9-42bb-b970-68f95840be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3df8efe-5908-4097-99e0-fcfbc8e178d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "import numpy as np\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57f33c8-2e76-41d0-8d5c-4e432526588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#api key 가져오기\n",
    "#로컬 아나콘다에서 실행하여 userdata.get이 아닌 load_dotenv 사용\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(verbose=True)\n",
    "\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d24db0-d89d-4fb2-972c-3cb9f89da9f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#huggingface 로그인\n",
    "from huggingface_hub import login\n",
    "login(HF_TOKEN, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6648236-f2e5-4a44-b542-ae00d30177f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorstore 저장할 경로 지정\n",
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef34790a-4fbb-4375-a4a1-8e83474da4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from pathlib import Path\n",
    "import json\n",
    "root = Path(\"판결문 데이터 위치\")\n",
    "folders = root.rglob(\"*.json\")\n",
    "\n",
    "docs = []\n",
    "\n",
    "for folder in folders:  \n",
    "    with open(folder,'r',  encoding = 'UTF-8') as f:\n",
    "        case = json.load(f)\n",
    "        \n",
    "    info = case.get(\"info\", {})\n",
    "    concerned = case.get(\"concerned\", {})\n",
    "    disposal = case.get(\"disposal\", {})\n",
    "    assrs = case.get(\"assrs\", {})\n",
    "    disposal = case.get(\"disposal\", {})\n",
    "    facts = case.get(\"facts\", {})\n",
    "    dcss = case.get(\"dcss\", {})\n",
    "    close = case.get(\"close\", {})\n",
    "\n",
    "    # 공통 metadata\n",
    "    metadata = {\n",
    "        \"case_number\": info.get(\"caseNo\"),\n",
    "        \"case_name\": info.get(\"caseNm\"),\n",
    "        \"court_name\": info.get(\"courtNm\"),\n",
    "        \"decision_date\": info.get(\"judmnAdjuDe\"),\n",
    "        \"case_field\": info.get(\"caseField\"),\n",
    "        \"relateLaword\": info.get(\"relateLaword\"),\n",
    "    }\n",
    "\n",
    "    acusrAssrs = \"원고의 주장 \" + \"\\n\".join(assrs.get(\"acusrAssrs\", []))\n",
    "    if acusrAssrs.strip():\n",
    "        docs.append(Document(\n",
    "            page_content=acusrAssrs,\n",
    "            metadata={**metadata, \"section\": \"원고의 주장\"}\n",
    "        ))\n",
    "\n",
    "    dedatAssrs = \"피고의 주장 \" + \"\\n\".join(assrs.get(\"dedatAssrs\", []))\n",
    "    if dedatAssrs.strip():\n",
    "        docs.append(Document(\n",
    "            page_content=dedatAssrs,\n",
    "            metadata={**metadata, \"section\": \"피고의 주장\"}\n",
    "        ))\n",
    "\n",
    "    # 사실관계 부분 합치기\n",
    "    facts_text = \"사실관계 \" + \"\\n\".join(facts.get(\"bsisFacts\", []))\n",
    "    if facts_text.strip():\n",
    "        docs.append(Document(\n",
    "            page_content=facts_text,\n",
    "            metadata={**metadata, \"section\": \"사실관계\"}\n",
    "        ))\n",
    "\n",
    "    # 법원의 판단 부분 합치기\n",
    "    dcss_text = \"법원의 판단 \" + \"\\n\".join(dcss.get(\"courtDcss\", []))\n",
    "    if dcss_text.strip():\n",
    "        docs.append(Document(\n",
    "            page_content=dcss_text,\n",
    "            metadata={**metadata, \"section\": \"법원의 판단\"}\n",
    "        ))\n",
    "\n",
    "    # 주문 부분\n",
    "    disposal_text = \"주문 \" + \"\\n\".join(disposal.get(\"disposalcontent\", []))\n",
    "    if disposal_text.strip():\n",
    "        docs.append(Document(\n",
    "            page_content=disposal_text,\n",
    "            metadata={**metadata, \"section\": \"주문\"}\n",
    "        ))\n",
    "\n",
    "    # 결론 부분\n",
    "    close_text = \"결론 \" + \"\\n\".join(close.get(\"cnclsns\", []))\n",
    "    if close_text.strip():\n",
    "        docs.append(Document(\n",
    "            page_content=close_text,\n",
    "            metadata={**metadata, \"section\": \"결론\"}\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164813d7-6405-4e63-9674-5b72efa8af7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d333ec8-f39b-49cc-96ee-eb83d98bac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c07453a-153f-4495-97ae-b917fcb216f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CharacterTextSplitter로 chunk 나누기\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1200, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20692b28-1a19-4161-998c-946dbee497ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in chunks:\n",
    "    if chunk.metadata:\n",
    "        for key, value in chunk.metadata.items():\n",
    "            if isinstance(value, list):\n",
    "                # 리스트를 쉼표로 구분된 문자열로 변환\n",
    "                chunk.metadata[key] = ', '.join(map(str, value))\n",
    "            elif isinstance(value, dict):\n",
    "                # 딕셔너리를 JSON 문자열로 변환\n",
    "                import json\n",
    "                chunk.metadata[key] = json.dumps(value, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e6a24-2125-4a83-81b7-4304beb1de21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Total number of chunks: {len(chunks)}\")\n",
    "print(f\"Document types found: {set(doc.metadata['case_name'] for doc in docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7581ec4c-e9c4-49f8-bd62-79d422a66583",
   "metadata": {},
   "outputs": [],
   "source": [
    "#임베딩 모델 파일 다운이 안되어서 git clone으로 직접 다운로드\n",
    "#!git clone https://huggingface.co/jhgan/ko-sroberta-multitask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56e1bb4-debd-48f3-a64a-a28628f04ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"./models/ko-sroberta-multitask\"  # 로컬 모델 경로\n",
    ")\n",
    "                                                 \n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-multitask\")\n",
    "# 로컬 모델이 아닌 huggingface 모델 지정시 자동 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6116edd9-6313-431a-846a-c8fee23c0586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3146f04a-25db-4b7e-9da4-337c755a6ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "# embeddings = HuggingFaceEmbeddings(model_name=\"jhgan/ko-sroberta-multitask\")\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8becfc4-aff5-4eb0-b2f8-f8a42d67745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = vectorstore._collection\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"The vectors have {dimensions:,} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cabc199-6c3d-4f77-a5f4-e38a2566bb62",
   "metadata": {},
   "source": [
    "# vectorstore 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc8287a-268d-42ce-bf0d-bbf3b193dc3f",
   "metadata": {},
   "source": [
    "강의에서 배포된 코드를 기반으로 수정\n",
    "\n",
    "RunnableWithMessageHistory와 같은 몇몇 부분은 강의 라이브러리 버전과 현재 사용중인 부분이맞지 않아서, \n",
    "\n",
    "완전히 갈아엎음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b30d94-e4b7-4258-96fa-56bfc5a5e9a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# 환경 변수 설정\n",
    "\n",
    "openrouter_url = \"https://openrouter.ai/api/v1\"\n",
    "\n",
    "# LLM 설정\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0.7, #숫자가 올라갈수록 ai의 답변 창의성 증가, 용도에 맞게 수치 설정\n",
    "    model_name=MODEL,\n",
    "    base_url=openrouter_url,\n",
    "    api_key=os.environ['OPENROUTER_API_KEY']\n",
    ")\n",
    "\n",
    "# Retriever 설정\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# 문서 포맷팅 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# 프롬프트 설정\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 질문에 답변하는 AI 어시스턴트입니다. 주어진 문서를 기반으로 답변하세요.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"문서:\\n{context}\\n\\n질문: {question}\")\n",
    "])\n",
    "\n",
    "# 체인 구성\n",
    "def get_context(input_dict):\n",
    "    question = input_dict[\"question\"]\n",
    "    docs = retriever.invoke(question)\n",
    "    return format_docs(docs)\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(context=get_context)\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 세션별 메모리 저장소\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# 대화 히스토리를 포함한 체인\n",
    "conversation_chain = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "# 사용 예시\n",
    "session_id = \"user123\"\n",
    "response = conversation_chain.invoke(\n",
    "    {\"question\": \"안녕하세요?\"},  # 딕셔너리로 전달\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(response)\n",
    "\n",
    "# 대화 계속\n",
    "response2 = conversation_chain.invoke(\n",
    "    {\"question\": \"이 문서에 대해 설명해주세요.\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b667bf-0d07-4402-af88-0318d30d2bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4b62f9-873e-4c64-a7d3-151bee58399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(question, history):\n",
    "    response = conversation_chain.invoke(\n",
    "    {\"question\": question},  # 딕셔너리로 전달\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9587aa7c-f889-4243-b32d-683b6d67de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.ChatInterface(chat, type=\"messages\").launch(inbrowser=True, share = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aee7840-8e60-44ba-890e-16961ec53d23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
